# Enable OTLP ingestion on the standard ports
distributor:
    receivers:
        otlp:
            protocols:
                grpc:
                    endpoint: "0.0.0.0:4317" # gRPC ingestion on port 4317
                http:
                    endpoint: "0.0.0.0:4318" # HTTP ingestion on port 4318

# (Optional) Expose the Tempo query API on port 3200
server:
    http_listen_port: 3200

storage:
    trace:
        backend: local # must be one of "gcs", "s3", "azure" or "local"
        wal:
            path: /var/tempo/wal # path for write-ahead log
        local:
            path: /var/tempo/blocks # path for block storage

metrics_generator:
    ring:
        kvstore:
            store: memberlist # Use gossip-based memberlist
    processor:
        span_metrics: {} # Enable span-metrics processor
        service_graphs: {} # Enable service-graphs processor
        local_blocks:
            flush_to_storage: true
            filter_server_spans: false # Run TraceQL metrics queries against all spans
    registry:
        external_labels:
            source: tempo
    storage:
        path: /var/tempo/generator/wal # WAL for metrics generation
        remote_write: # Push metrics and exemplars to Prometheus
          - url: http://prometheus:9090/api/v1/write
            send_exemplars: true # Include exemplars in remote-write
    traces_storage:
        path: /var/tempo/generator/traces # Needed for buffering traces for metrics

overrides:
    defaults:
        metrics_generator:
            processors:
              - span-metrics # Activate span-metrics for the default tenant
              - service-graphs # Activate service-graphs for the default tenant
              - local-blocks # Enable local-blocks processor for TraceQL metrics

# Configure TraceQL metrics query options
query_frontend:
    metrics:
        concurrent_jobs: 8
        target_bytes_per_job: 1.25e+09 # ~1.25GB
